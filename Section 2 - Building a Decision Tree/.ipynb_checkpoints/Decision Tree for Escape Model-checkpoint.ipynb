{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Trees for Rulesetting\n",
    "\n",
    "We will use a decision tree to determine if the prior data collected in section one is within a specified ruleset and in or out of the bag.\n",
    "\n",
    "While many ML algorithms are considered 'black boxes' a decision tree is much more human readable and allows for us to better determine why it predicts or acts in the way that it does.\n",
    "\n",
    "This exercise falls within the use of supervised machine learning and is using a model we will train on training data to make predicitons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [['a', 0, 'good'], ['a', 101, 'good'], ['b', -1, 'bad']] #['letter', 'number', 'class']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "you can see how if you were to classify the 3 data points above as either good or bad, that you could choose to say if letter == a then good or you could choose if number > -1 then good, else bad.\n",
    "\n",
    "Either way this is how decision trees work by splitting hte data into subgroups and using the features provided (like letter and number) to make a prediction on class.\n",
    "\n",
    "As data sets grow larger and features become more plentiful you will need better methods for splittign the tree and accouting for the increase in entropy (the measure of uncertainty) in the model.\n",
    "\n",
    "We can also represent trees with dictionaries shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = {'letter': {'a': 'good', 'b': 'bad'}, 'number':{0: 'good', 101: 'good', -1: 'bad'}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree['letter']['a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree['letter']['b']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree['number'][0] #can replace with 0 or -1; anything else will return a key error since we don't use conditionals yet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can sort the data points into groups and push the data point on to the next decision in the tree. \n",
    "\n",
    "Lets first set up a partition over numbers, then a second grouping based on letter to place these datum (singular points of data) into thier final groupings as good or bad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_group = []\n",
    "bad_group = []\n",
    "\n",
    "for key, value in tree.items():\n",
    "    if key == 'number':\n",
    "        for k,v in value.items():\n",
    "            if k > -1:\n",
    "                good_group.append(k)\n",
    "            else:\n",
    "                bad_group.append(k)\n",
    "    if key == 'letter':\n",
    "        for k,v in value.items():\n",
    "            if k == 'a':\n",
    "                good_group.append(k)\n",
    "            else:\n",
    "                bad_group.append(k)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(good_group,bad_group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To figure out the entropy (uncertainty) of our dataset, we use the proportion of our data within each category or feature.\n",
    "\n",
    " $ H_{(entropy)} = - \\sum^n_{i=1} P(X_i) * log_2 P(X_i)  $\n",
    "\n",
    "Log base 2 provides us a range between 0 and 1.\n",
    "\n",
    "Now that we have a basis for understanding entropy and calculating split points, we can attempt to apply this to our data we pickled from section 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('../Section 1 - Code a Turtle Out of a Bag/data_rand', 'rb') as f:\n",
    "    L = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L #[X,Y,Out of the box or not]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def escaped_turtles(data):\n",
    "    turtle_list = []\n",
    "    for i in range(len(data)):\n",
    "        if data[i][-1] == True:\n",
    "            turtle_list.append(data[i][:-1])\n",
    "    return turtle_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import math\n",
    "import operator\n",
    "\n",
    "def entropy(data):\n",
    "    frequency = collections.Counter([item[-1] for item in data]) # output == ({False: 73, True: 10})\n",
    "    def item_entropy(category):\n",
    "        ratio = float(category)/len(data) #ratio of category to len of dataset\n",
    "        return -1 * ratio * math.log2(ratio) #neg log base 2 of this item\n",
    "    return sum(item_entropy(c) for c in frequency.values()) #sum it all up to return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(entropy(L))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_feature_for_split(data):\n",
    "    baseline = entropy(data)\n",
    "    def feature_entropy(f):\n",
    "        def e(v):\n",
    "            partitioned_data = [d for d in data if d[f] == v]\n",
    "            proportion = (float(len(partitioned_data)) / float(len(data)))\n",
    "            return proportion * entropy(partitioned_data)\n",
    "        return sum(e(v) for v in set([d[f] for d in data]))\n",
    "    features = len(data[0]) - 1\n",
    "    informaiton_gain = [baseline - feature_entropy(f) for f in range(features)]\n",
    "    best_feature, best_gain = max(enumerate(informaiton_gain), key=operator.itemgetter(1))\n",
    "    return best_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_feature_for_split(L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def potential_leaf_node(data):\n",
    "    '''\n",
    "    returns a tuple of the most common category and a count (category, count)\n",
    "    '''\n",
    "    count = collections.Counter([i[-1] for i in data])\n",
    "    return count.most_common(1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "potential_leaf_node(L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tree(data, label):\n",
    "    category, count = potential_leaf_node(data)\n",
    "    if count == len(data):\n",
    "        return category\n",
    "    node = {}\n",
    "    feature = best_feature_for_split(data)\n",
    "    feature_label = label[feature]\n",
    "    node[feature_label] = {}\n",
    "    classes = set([d[feature] for d in data])\n",
    "    for c  in classes:\n",
    "        partitioned_data = [d for d in data if d[feature] == c]\n",
    "        node[feature_label][c] = create_tree(partitioned_data, label)\n",
    "    return node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(tree, label, data):\n",
    "    root = list(tree.keys())[0]\n",
    "    node = tree[root]\n",
    "    index = label.index(root)\n",
    "    for k in node.keys():\n",
    "        if data[index] == k:\n",
    "            if isinstance(node[k],dict):\n",
    "                return classify(node[k], label, data)\n",
    "            else:\n",
    "                return node[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def as_rule_str(tree, label, ident=0):\n",
    "    space_ident = '  ' * ident\n",
    "    s = space_ident\n",
    "    root = list(tree.keys())[0]\n",
    "    node = tree[root]\n",
    "    index = label.index(root)\n",
    "    for k in node.keys():\n",
    "        s += 'if ' + label[index] + ' = ' + str(k)\n",
    "        if isinstance(node[k], dict):\n",
    "            s += ':\\n' + space_ident + as_rule_str(node[k], label, idnet + 1)\n",
    "        else:\n",
    "            s += ' then ' + str(node[k]) + ('.\\n' if ident == 0 else ', ')\n",
    "    if s[-2:] == ', ':\n",
    "        s = s[:2]\n",
    "    s+= '\\n'\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [[0,0, False], [1,0,False], [0,1,True], [1,1,True]]\n",
    "label = ['x','y','out']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree =  create_tree(data, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(as_rule_str(tree, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classify(tree, label, [1,1]))\n",
    "print(classify(tree, label, [0,0]))\n",
    "print(classify(tree, label, [1,2])) # cant classify what it hasn't seen\n",
    "print(classify(tree, label, [3,4])) # cant classify what it hasn't seen\n",
    "print(classify(tree, label, [-1,-1])) # cant classify what it hasn't seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = create_tree(L, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(as_rule_str(tree, label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is a ton of rules if we use the data from our prior section. We need to generalize ther rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "Y = []\n",
    "for i in L:\n",
    "    X.append(i[0])\n",
    "    Y.append(i[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_edges(tree, label, X, Y):\n",
    "    X.sort()\n",
    "    Y.sort()\n",
    "    diagonals = [i for i in set(X).intersection(set(Y))]\n",
    "    diagonals.sort()\n",
    "    L = [classify(tree, label, [d,d]) for d in diagonals]\n",
    "    low = L.index(False)\n",
    "    min_x = X[low]\n",
    "    min_y = Y[low]\n",
    "    high = L[::-1].index(False)\n",
    "    max_x = X[len(X)-1 - high]\n",
    "    max_y = Y[len(Y)-1 - high]\n",
    "    \n",
    "    return (min_x, min_y), (max_x, max_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_edges(tree, label, X, Y) # you can use this to create a new rule to classify a point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_coord_bounds = find_edges(tree, label, X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_coord_bounds[0][0] #minx\n",
    "pred_coord_bounds[0][1] #miny\n",
    "pred_coord_bounds[1][0] #maxx\n",
    "pred_coord_bounds[1][1] #maxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs(pred_coord_bounds[0][0])+abs(pred_coord_bounds[1][0]) #xspan\n",
    "abs(pred_coord_bounds[0][1])+abs(pred_coord_bounds[1][1]) #yspan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import turtle as tl\n",
    "\n",
    "def draw_bag():\n",
    "    tl.shape('turtle')\n",
    "    tl.color('blue')\n",
    "    tl.pen(pencolor = 'blue', pensize = 5)\n",
    "    tl.penup()\n",
    "    tl.goto(-35,35)\n",
    "    tl.pendown()\n",
    "    tl.right(90) # angle of turn\n",
    "    tl.forward(70) #length of line\n",
    "    tl.left(90)\n",
    "    tl.forward(70)\n",
    "    tl.left(90)\n",
    "    tl.forward(70)\n",
    "\n",
    "def draw_bag_guess(pred_coord_bounds):\n",
    "    chad = tl.Turtle() \n",
    "    chad.shape('turtle')\n",
    "    chad.color('red')\n",
    "    chad.pen(pencolor = 'red', pensize = 5)\n",
    "    chad.penup()\n",
    "    chad.goto(pred_coord_bounds[0][0],pred_coord_bounds[1][1])\n",
    "    chad.pendown()\n",
    "    chad.right(90) # angle of turn\n",
    "    chad.forward(abs(pred_coord_bounds[0][1])+abs(pred_coord_bounds[1][1])) #length of line\n",
    "    chad.left(90)\n",
    "    chad.forward(abs(pred_coord_bounds[0][0])+abs(pred_coord_bounds[1][0]))\n",
    "    chad.left(90)\n",
    "    chad.forward(abs(pred_coord_bounds[0][1])+abs(pred_coord_bounds[1][1]))\n",
    "    chad.left(90)\n",
    "    chad.forward(abs(pred_coord_bounds[0][0])+abs(pred_coord_bounds[1][0]))\n",
    "    \n",
    "def plot_turtles(data):\n",
    "    billy = tl.Turtle()\n",
    "    billy.shape('turtle')\n",
    "    billy.color('green')\n",
    "    plot_list = escaped_turtles(data)\n",
    "    for i in plot_list:\n",
    "        billy.penup()\n",
    "        billy.setposition(i[0], i[1])\n",
    "        billy.stamp()\n",
    "\n",
    "def plot_new_turtles(data):\n",
    "    '''\n",
    "    input a list of xy coords [[x,y]]\n",
    "    '''\n",
    "    jake = tl.Turtle()\n",
    "    jake.shape('turtle')\n",
    "    jake.color('black')\n",
    "    plot_list = data\n",
    "    for i in plot_list:\n",
    "        jake.penup()\n",
    "        jake.setposition(i[0], i[1])\n",
    "        jake.stamp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_classifier(tree, label, data, pred_point):\n",
    "    X = []\n",
    "    Y = []\n",
    "    for i in data:\n",
    "        X.append(i[0])\n",
    "        Y.append(i[1])\n",
    "    min_x = find_edges(tree, label, X, Y)[0][0]\n",
    "    min_y = find_edges(tree, label, X, Y)[0][1]\n",
    "    max_x = find_edges(tree, label, X, Y)[1][0]\n",
    "    max_y = find_edges(tree, label, X, Y)[1][1]\n",
    "    x = pred_point[0]\n",
    "    y = pred_point[1]\n",
    "    if (min_x < x < max_x) and (min_y < y < max_y): \n",
    "        return 'Inside', True\n",
    "    else:\n",
    "        return 'Outside', False\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(new_classifier(tree, label, L, [-5, 5]))\n",
    "print(new_classifier(tree, label, L, [-36, 5]))#change points around to see if it's within or outside the bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    tl.setworldcoordinates(-70.,-70.,70.,70.)\n",
    "#     tl.ht()\n",
    "    tl.speed(10)\n",
    "#     tl.tracer(0,0) #ensure update is uncomented if you'd like to see the paths \n",
    "    draw_bag()\n",
    "    draw_bag_guess(pred_coord_bounds)\n",
    "    time.sleep(3)\n",
    "    plot_turtles(L)\n",
    "    plot_new_turtles([[-5,5]])\n",
    "    time.sleep(3)\n",
    "    plot_new_turtles([[-36,5]])\n",
    "    tl.mainloop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a new classifier that uses the edges found from our training data to determin the bounding box for our decision tree!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
